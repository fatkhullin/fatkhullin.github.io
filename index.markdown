---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
---
<table>
  <tr>
    <td style="border:none">
      <a href="#about"><h3>About</h3></a>
    </td>
    <td style="border:none">
      <a href="#publ"><h3>Publications</h3></a>
    </td>
    <td style="border:none">
      <a href="#cont"><h3>Contact</h3></a>
    </td>
  </tr>
</table>

---
## About me {#about}

I am a second-year PhD student at ETH Zurich and ETH AI Center supervised by Prof. Niao He and Prof. Francesco Corman. My research interests include large-scale optimization, reinforcement learning and federated learning.

Previously, I had an honor to work with Prof. Boris Teodorovich Polyak and Prof. Peter Richtárik.


## Publications {#publ}

- Ilyas Fatkhullin, Alexander Tyurin, Peter Richtárik. [Momentum Provably Improves Error Feedback!](https://arxiv.org/abs/2305.15155), NeurIPS 2023.

- Junchi Yang, Xiang Li, Ilyas Fatkhullin, Niao He. <b>Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods</b>, NeurIPS 2023.

- Anas Barakat, Ilyas Fatkhullin, Niao He. <b>Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space</b>, ICML 2023.

- Ilyas Fatkhullin, Anas Barakat, Anastasia Kireeva, Niao He. <b>Stochastic Policy Gradient Methods: Improved Global Convergence and Sample Complexity</b>, ICML 2023.

- Ilyas Fatkhullin, Jalal Etesami, Niao He, Negar Kiyavash. <b>Sharp Analysis of Stochastic Optimization under Global Kurdyka-Łojasiewicz Inequality</b>, NeurIPS 2022.

- Peter Richtárik, Igor Sokolov, Ilyas Fatkhullin, Elnur Gasanov, Eduard Gorbunov, Zhize Li. <b>3PC: Three Point Compressors for Communication-Efficient Distributed Training and a Better Theory for Lazy Aggregation</b>, ICML 2022 (spotlight).

- Ilyas Fatkhullin, Igor Sokolov, Eduard Gorbunov, Zhize Li, Peter Richtárik. <b>EF21 with Bells & Whistles: Practical Algorithmic Extensions of Modern Error Feedback</b>, OptML workshop at NeurIPS 2021. Preprint: arXiv:2110.03294v1 (2021).

- Peter Richtárik, Igor Sokolov, Ilyas Fatkhullin. <b>EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback</b>, NeurIPS 2021 (oral).

- Ilyas Fatkhullin, Boris Polyak. <b>Optimizing Static Linear Feedback: Gradient Method</b>, SIAM Journal on Control and Optimization 59, 3887-3911 (2021).

- Boris Polyak, Ilyas Fatkhullin. <b>Use of Projective Coordinate Descent in the Fekete Problem</b>, Comput. Math. and Math. Phys. 60, 795–807 (2020).


## Contact {#publ}

Current address: ETH AI Center, OAT X 14, Andreasstrasse 5, 8092 Zürich, Switzerland

E-mail: name.last_name(at)ai(dot)ethz(dot)ch
